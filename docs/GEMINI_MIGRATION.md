# ðŸš€ MigraÃ§Ã£o para Google Gemini 2.0 Flash

## ðŸ“Š Resumo da MigraÃ§Ã£o

MigraÃ§Ã£o de **OpenAI GPT-4** para **Google Gemini 2.0 Flash** como LLM principal para geraÃ§Ã£o de prompts cinematogrÃ¡ficos.

### ðŸ’° BenefÃ­cios:
- **95% mais barato** que GPT-4
- **Melhor para tarefas criativas** e prompts visuais
- **Mais rÃ¡pido** (menor latÃªncia)
- **Excelente para narrativas** cinematogrÃ¡ficas

---

## ðŸ“‹ ComparaÃ§Ã£o de Custos

| Modelo | Input ($/1M tokens) | Output ($/1M tokens) | Economia |
|--------|---------------------|----------------------|----------|
| **Gemini 2.0 Flash** | $0.075 | $0.30 | **Baseline** |
| GPT-4o-mini | ~$0.15 | ~$0.60 | 2x mais caro |
| GPT-4 | ~$1.50 | ~$6.00 | **20x mais caro** |

### ðŸ’¡ Economia Estimada:
- **83% de reduÃ§Ã£o** nos custos de IA
- **Qualidade equivalente ou superior** para prompts visuais
- **Processamento mais rÃ¡pido**

---

## ðŸ”§ AlteraÃ§Ãµes Implementadas

### 1. **VariÃ¡veis de Ambiente (.env)**

```bash
# API do Google Gemini (LLM Principal)
GEMINI_API_KEY=AIzaSyD6L3PQI5MSmiQvosOrhcQllU4_O3UplP4
GOOGLE_API_KEY=AIzaSyD6L3PQI5MSmiQvosOrhcQllU4_O3UplP4
GEMINI_MODEL="gemini-2.0-flash-exp"
DEFAULT_LLM="gemini-2.0-flash-exp"

# OpenAI (Mantida como fallback)
OPENAI_API_KEY=sk-proj-...
FALLBACK_LLM="gpt-4o-mini"
```

### 2. **GitHub Secrets**

Adicione no repositÃ³rio (Settings â†’ Secrets and variables â†’ Actions):

```
GEMINI_API_KEY=AIzaSyD6L3PQI5MSmiQvosOrhcQllU4_O3UplP4
```

### 3. **Dependencies (requirements.txt)**

```python
# Google Gemini (Principal)
langchain-google-genai>=0.0.5
google-generativeai>=0.3.0

# OpenAI (Fallback)
openai==1.3.0
langchain-openai>=0.0.2
```

### 4. **ConfiguraÃ§Ã£o do LLM (orchestration/llm_config.py)**

```python
from orchestration.llm_config import get_llm_with_fallback

# Usa Gemini por padrÃ£o, fallback para OpenAI se necessÃ¡rio
llm = get_llm_with_fallback()
```

---

## ðŸŽ¯ EstratÃ©gia de Uso

### **90-95% das tarefas: Gemini 2.0 Flash**
- âœ… DivisÃ£o de narrativa em cenas
- âœ… GeraÃ§Ã£o de prompts cinematogrÃ¡ficos
- âœ… ExtraÃ§Ã£o de elementos visuais
- âœ… Refinamento de prompts
- âœ… ValidaÃ§Ã£o bÃ¡sica de coerÃªncia

### **5-10% das tarefas: GPT-4o-mini (Fallback)**
- ðŸ” ValidaÃ§Ã£o final crÃ­tica (se necessÃ¡rio)
- ðŸŽ¯ Casos onde precisar de nuances especÃ­ficas

---

## ðŸ“ Como Usar no CÃ³digo

### **OpÃ§Ã£o 1: AutomÃ¡tico (Recomendado)**
```python
from orchestration.llm_config import get_llm_with_fallback

# Tenta Gemini, fallback para OpenAI se falhar
llm = get_llm_with_fallback()

response = llm.invoke("Crie um prompt cinematogrÃ¡fico para...")
```

### **OpÃ§Ã£o 2: ExplÃ­cito**
```python
from orchestration.llm_config import get_llm_client

# ForÃ§ar Gemini
llm_gemini = get_llm_client("gemini")

# ForÃ§ar OpenAI
llm_openai = get_llm_client("openai")
```

### **OpÃ§Ã£o 3: LangChain Direto**
```python
from langchain_google_genai import ChatGoogleGenerativeAI
import os

llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    google_api_key=os.getenv("GEMINI_API_KEY"),
    temperature=0.9,
    max_output_tokens=8192
)
```

---

## ðŸŽ¬ Prompts CinematogrÃ¡ficos

### **Template Otimizado para Gemini:**

```python
from orchestration.llm_config import CINEMATIC_PROMPT_TEMPLATE

prompt = CINEMATIC_PROMPT_TEMPLATE.format(
    scene_description="Uma mulher caminhando em uma cidade futurista",
    negative_prompts="low quality, blurry, distorted"
)

response = llm.invoke(prompt)
```

### **Exemplo de SaÃ­da:**

```
PROMPT: A woman walking through a futuristic cyberpunk city at night, 
neon lights reflecting on wet streets, shot on ARRI Alexa with 35mm 
anamorphic lens, Blade Runner 2049 style, dramatic chiaroscuro lighting, 
golden hour backlight, rule of thirds composition, 8K, photorealistic, 
highly detailed, melancholic atmosphere

NEGATIVE: low quality, blurry, distorted, amateur, overexposed, 
underexposed, cartoon, anime, painting
```

---

## ðŸ”„ MigraÃ§Ã£o de CÃ³digo Existente

### **Antes (OpenAI):**
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)
```

### **Depois (Gemini):**
```python
from orchestration.llm_config import get_llm_with_fallback

# AutomÃ¡tico: Gemini com fallback para OpenAI
llm = get_llm_with_fallback()
```

---

## ðŸ§ª Teste a ConfiguraÃ§Ã£o

```bash
# Testar configuraÃ§Ã£o do LLM
python orchestration/llm_config.py

# SaÃ­da esperada:
# ======================================================================
# ðŸ¤– CONFIGURAÃ‡ÃƒO DO LLM
# ======================================================================
# Provider Principal: gemini
# Modelo Principal: gemini-2.0-flash-exp
# Modelo Fallback: gpt-4o-mini
# Gemini API Key: âœ… Configurada
# OpenAI API Key: âœ… Configurada
# ======================================================================
```

---

## ðŸ“Š Monitoramento de Custos

### **Estimativa por ExecuÃ§Ã£o:**

Assumindo 1 filme com 8 cenas:
- **Prompts de entrada:** ~2K tokens por cena = 16K tokens
- **Prompts de saÃ­da:** ~500 tokens por cena = 4K tokens

**Custo com Gemini:**
- Input: 16K tokens Ã— $0.075/1M = $0.0012
- Output: 4K tokens Ã— $0.30/1M = $0.0012
- **Total: ~$0.0024 por filme**

**Custo com GPT-4:**
- Input: 16K tokens Ã— $1.50/1M = $0.024
- Output: 4K tokens Ã— $6.00/1M = $0.024
- **Total: ~$0.048 por filme**

**Economia: 95%** ðŸ’°

---

## âš ï¸ Troubleshooting

### **Erro: "GEMINI_API_KEY nÃ£o encontrada"**
```bash
# Verifique se a chave estÃ¡ no .env
cat open3d_implementation/.env | grep GEMINI

# Adicione se nÃ£o existir
echo "GEMINI_API_KEY=AIzaSyD6L3PQI5MSmiQvosOrhcQllU4_O3UplP4" >> open3d_implementation/.env
```

### **Erro: "Module 'langchain_google_genai' not found"**
```bash
# Instale as dependÃªncias
pip install langchain-google-genai google-generativeai
```

### **Fallback para OpenAI nÃ£o funciona**
```bash
# Verifique se OpenAI API Key estÃ¡ configurada
echo $OPENAI_API_KEY
```

---

## ðŸš€ PrÃ³ximos Passos

1. âœ… **Testar localmente** com `python orchestration/llm_config.py`
2. âœ… **Adicionar GEMINI_API_KEY** no GitHub Secrets
3. âœ… **Fazer commit e push** das alteraÃ§Ãµes
4. âœ… **Testar no CI/CD** com workflow automÃ¡tico
5. âœ… **Monitorar custos** e qualidade dos prompts

---

## ðŸ“š Recursos

- [Gemini API Documentation](https://ai.google.dev/docs)
- [LangChain Google GenAI](https://python.langchain.com/docs/integrations/chat/google_generative_ai)
- [Gemini Pricing](https://ai.google.dev/pricing)

---

## ðŸ’¡ Dicas de OtimizaÃ§Ã£o

### **1. Use temperatura alta para criatividade:**
```python
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0.9,  # Mais criativo
    top_p=0.95,
    top_k=40
)
```

### **2. Especifique o contexto cinematogrÃ¡fico:**
```python
system_message = """VocÃª Ã© um diretor de fotografia especializado em 
criar prompts ultra-detalhados para geraÃ§Ã£o de imagens cinematogrÃ¡ficas."""

messages = [
    ("system", system_message),
    ("human", "Crie um prompt para...")
]
```

### **3. Use negative prompts robustos:**
```python
negative_prompts = """low quality, blurry, distorted, amateur, 
overexposed, underexposed, cartoon, anime, painting, sketch, 
CGI, 3D render, unrealistic"""
```

---

**Data da MigraÃ§Ã£o:** 31 de Outubro de 2025  
**VersÃ£o:** 1.0  
**Status:** âœ… Implementado
